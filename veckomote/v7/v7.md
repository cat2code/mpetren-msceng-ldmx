## Veckomöte v6

**Deltagare:** Eliot, Lene-Kristian

### Check-in
* Det e bra med mig! Blev både sjuk i slutet av förra veckan och upptagen med annat som tog tid från studierna (som jag inte hann ta igen under helgen) men nu är man tillbaks sedan måndags. Rutinen att dyka upp här, mötena och alla de nya ansiktena här börjar bli väldigt bekant och detta är fortsatt toppen!

#### Workshop v6 bullet points
* Wins. 
    * Clarity on GNN vs Transformer architecture choices, 
    * found relevant papers on ML based reconstruction similar to my project
* Help/Stuck
    * Was interrupted end of last week and got sick as well, did not manage to catch up during weekend
    * Struggling on using ClusterAnalyzer from ldmx-sw but not ''stuck'' per-say
* Focus this week:
    * Producing nice histogram plots with ClusterAnalyzer, 
    * Moving onto using the newly implemented CLUE + ParticleFlow analyzers (?) Lene-Kristian recently implemented

* **Goal (thesis deliverable):** robust **electron counting in ECAL under pile-up**, ideally with interpretable intermediate objects (showers/clusters) and clear performance metrics.

* **Key orientation from CMS PF/MLPF:**

  * CMS does **tracking + calorimeter clustering first**, then applies a **global interpretation/linking** step (PF or ML-based PF).
  * Takeaway: clustering-first is a standard, scalable intermediate representation; not “cheating”.

* **Current toy model status:**

  * Toy model treats **each reconstructed hit as a node** in a GNN and learns instance clustering end-to-end.
  * Pro: maximal flexibility; directly learns segmentation.
  * Con: graph size and training complexity scale poorly; harder to control failure modes; less aligned with how experiments structure reconstruction.

* **Two strategic directions:**

  * **Option 1: hit-level learned clustering (replace CLUE)**

    * Input: ECAL hits → ML learns clustering/segmentation → showers → count electrons.
    * Pros: potentially best ultimate performance if it works; “end-to-end” shower separation.
    * Cons: higher risk, heavier engineering/training, harder debugging; may require more data/compute/tuning; less predictable in 3-month solo scope.
  * **Option 2: cluster-first + ML refinement (CLUE/topo → ML)**

    * Input: ECAL hits → **CLUE (or simple topo clustering)** → proto-clusters → ML merges/splits/refines + classifies → count electrons.
    * Pros: lower risk; scalable; easier debugging/ablation; closer to PF/MLPF philosophy; faster path to a useful LDMX deliverable.
    * Cons: depends on upstream cluster quality; ceiling set by clustering if refinement isn’t strong enough.

* **Why I currently favor Option 2 (practical thesis constraints):**

  * Fits **3-month** timeline and solo development.
  * Produces immediately useful outputs for LDMX: quantified **CLUE failure modes** (merge/split under pile-up) + an ML module that improves them.
  * Easier to iterate: can start with simple cluster features and gradually add complexity (layer profiles, shapes, timing, etc.).
  * Clear baseline comparison and reproducibility: “CLUE-only” vs “CLUE+ML”.

* **Concrete Option 2 plan (high-level):**

  * Step 1: Implement and validate **CLUE baseline** on our datasets; define metrics (count accuracy, merge/split rates vs pile-up).
  * Step 2: Build **cluster-level feature set** (energy sum, centroid, RMS/shower shapes, hit multiplicity, depth/layer summaries).
  * Step 3: ML refinement on cluster graph:

    * Predict **cluster–cluster links** (should merge?) + union-find, or
    * Predict **split/merge decisions** + per-cluster “electron-likeness”.
  * Step 4: Optional extension: condition on **tracker features** (if it helps disambiguation).

* **Proposed discussion questions for supervisor:**

  * Do we prioritize **lower risk + usable baseline** (Option 2) over a potentially higher-ceiling but riskier hit-level approach (Option 1)?
  * Which upstream clustering should be “official baseline”: **CLUE** only, or also simple topo clustering for comparison?
  * What is the preferred primary metric: **exact electron multiplicity**, or also shower-level purity/efficiency and merge/split diagnostics?
  * Is adding tracker information in-scope, or should we commit to **ECAL-only** for the thesis and treat tracker as stretch goal?


### Punkter till nästa vecka
* Debug PFlow/PileupFinder crash
  * Gör bug report

* Extrahera data från LDMX simulering (.root filer) som input till en ML arkitektur?
  * Ta inspiration från LDMX ParticleNet
  * Plocka ut 2d projektion kanske :) 

* Läsa mig in i hur track kan utnyttjas i min reconstruction-modell
  * Kolla paper jag hittade förra veckan
