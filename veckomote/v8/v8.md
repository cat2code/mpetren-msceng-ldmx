## Veckomöte v6

**Deltagare:** Eliot, Lene-Kristian

### Check-in
* Det e bra med mig! Senaste veckan för mig har bestått av 9-17 exjobb och sedan spex på fritid (Jesperspexet). Sista föreställningarna är i helgen, något jag ser fram emot! 
* Det finns många kandidat/masterstudenter till grannar, riktigt skoj, och jag har försökt assistera lite grand när det dykt upp frågor kring kodmiljö/ldmx-sw.
  * Det är bevisligen en tung uppförsbacke och knepigt med kodmiljö, vilket jag förstår när man som kandidatstudent har windows+wsl+docker+terminal som nya koncept att orientera sig kring. 
* Jobbmässigt den senaste veckan har min "headspace" varit kring att visualisera/brainstorma hur ML-baserad reconstruction kan fungera/vara nyttig för LDMX, och det är något jag vill diskutera idag!
  * Jag har läst och försökt ta del av papers/material relaterat till MLPF (Joseep Pata, et al) och försökt relatera det till detta projektet och LDMX. För mig känns det som att deras problemställning/ingång är väldigt lik vår och jag har en känsla av att det finns mycket att hämta härifrån. Detta har tagit min uppmärksamhet och skiftat mina focus-points inför denna veckan, for better or wose är upp till bevis... Vi diskuterar detta på punkten nedantill. 

#### W7 (från veckans workshpo)
* Wins
    * successfully got working wirh clusteranalyzer in ldmx-sw validation samples and produced some histograms (goal from last week)
    * I improved my workspace with my IDE and I have a nice set up for coding
    * Lene-Kristian and I found a bug and I made my first git issue report and correspnding merge req referenced to the issue. 
    * I made a simple toy model for my project with a gnn set to a classification task on 2D gaussian blobs. 

* Help/Stuck
    * nothing definitive at the moment
    * I might find issues in my focus-points this week and might need help from someone here or in ”worst case” from someone across the atlantic who implemented particlenet in ldmx-sw

* Focus
    * take inspiration of ways to extract ldmx-sw .root files output as input for a neural network architecure (presumably in python torch). Take inspiration from the particlenet implementation in ldmx-sw
    * produce a first example of using NN on .root data as input and attempt to design a very simple gnn model on that data
    * play around more with analyzers in it_pileup validation samples and further familiarization with the ldmx-sw framework
    * perhaps develop my toy example further and implement 3d space (though it might be unnecessary/wasted time).

* Diskussion/brainstorm ML modell för LDMX med anledning av MLPF

  * **Mål (thesis):** robust **reconstruction i ECAL under pile-up** + tydliga metrics + jämförelse mot baseline. 
    * (!) Men vi har även diskuterat att inkludera track-info bör vara ideellt och en bra utökning/vidareutveckling. Det finns inget värde i att begränsa sig till ECal (?) (dock är det förmodligen bäst att börja med denna del av detektorn). 

  * **Insikt från CMS PF/MLPF:** de kör **clustering först** (calo clusters) + tracking, och gör sedan **global interpretation/linking** (ML). Clustering-first ser ut att vara standard. (se flowchart i Miro)

  * **Toy model idag:** **hit-level GNN** (nodes = reconstructed hits) som lär sig clustering och tilldelar noder till cluster A/B/C eller noise. 

    * I princip en ersättning till rule-based clustering
    * Tungt (N hits). Mindre “experiment-lik” pipeline? Vad är syftet?

  * **Två vägar:**

    * **Option 1:** hit-level learned clustering (ersätta CLUE) (endast ECal -> local reconstruction)

      * hits → GNN → electron count + CLUE metrics
      * (-) Hög compute
      * (-) Ifrågasatt relevans jämfört med vad folk gör inom HEP?

    * **Option 2 (föredra?):** cluster-first ("pre-processing") + ML refinement (ECal + track (+ ?HCal) -> global reconstruction)

      * A: hits → **CLUE/clustering** , B: track, A+B → ML (merge/split/refine + classify) → count
      * (+) Lägre compute
      * (+) närmare PF/MLPF, levererar något mer sannolikt nyttigt för LDMX?
      * (-) beroende av upstream cluster quality

  * **Är option 2 rimligast?**

    * Angriper fortfarande samma problem och bibehåller tydlig baseline jämförelse (“PF/CLUE-only”)
    * Potential till konkret nytta?
    * ... eller har vi varit på spåret av "option 2" hela tiden egentligen? Jag kanske tänker för långt in i framtiden? 

  * **Option 2 mer konkret:**

    * 1. CLUE baseline + metrics: **count accuracy**, **merge/split rate**, vs pile-up/hit multiplicity
    * 2. cluster features: E_sum, centroid, shower shapes (RMS), N_hits, depth/layer summaries
    * 3. ML på cluster-graph
    * 4. Add **tracker context**
      * Attention mechanism, lägga till tracker-nodes fully connected med resterande noder

  * **Diskussionspunkter**

    * allt ovan
    * vill vi optimera för **deliverable** (Option 2) eller undersökning av GNN applicerat på high granurality data (Option 1)?
    * baseline: bara **CLUE** och/eller **PF**?
    * primära metrics att jobba emot att modellen ska ha i sin output?
    * tracker context: in-scope eller stretch?


### Punkter till nästa vecka
* 